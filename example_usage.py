"""
Example usage of the SQL Generation Pipeline.

This script demonstrates how to use the pipeline programmatically
using the existing components (LLMasJudge, LLMsql, LLMmerge, SQLTranslator)
and shows various configuration options.
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

# Import existing components directly
from model.LLMasJudge import LLMasJudgeSystem
from model.LLMsql import SQLLLMGenerator, SQLGenerationConfig, SQLDialect
from model.LLMmerge import LLMSQLMergerSystem
from SQLTranlator.sql_translator import SQLTranslator, SQLDialect as TranslatorDialect


def basic_example():
    """Basic usage example using existing components directly."""
    print("üöÄ Basic SQL Generation Example")
    print("=" * 50)
    
    start_time = time.time()
    
    # Define input
    prompt = "Find all users who registered in the last 30 days and have made at least 3 purchases"
    descriptions = [
        "users table contains: id, username, email, registration_date, status",
        "purchases table contains: id, user_id, product_id, purchase_date, amount",
        "products table contains: id, name, category, price"
    ]
    
    try:
        # Step 1: Initialize LLM Judge for prompt variants and relevance
        print("Step 1: Generating prompt variants...")
        judge_system = LLMasJudgeSystem()
        
        # Generate prompt variants
        rewrite_result = judge_system.rewrite_text(prompt)
        variants = []
        if rewrite_result and "text1" in rewrite_result:
            variants = [rewrite_result["text1"], rewrite_result["text2"], rewrite_result["text3"]]
        else:
            variants = [prompt]  # fallback
        
        print(f"  Generated {len(variants)} variants")
        
        # Step 2: Evaluate relevance
        print("Step 2: Evaluating relevance...")
        relevant_descriptions = []
        for desc in descriptions:
            # Check relevance using majority vote from variants
            relevance_votes = []
            for variant in variants:
                try:
                    is_relevant = judge_system.judge_relevance(variant, desc)
                    relevance_votes.append(is_relevant)
                except:
                    relevance_votes.append(True)  # conservative fallback
            
            if sum(relevance_votes) > len(relevance_votes) / 2:
                relevant_descriptions.append(desc)
        
        print(f"  Found {len(relevant_descriptions)} relevant descriptions")
        
        # Step 3: Generate SQL
        print("Step 3: Generating SQL...")
        sql_config = SQLGenerationConfig(
            model_name="microsoft/phi-4-mini-instruct",
            max_new_tokens=512,
            temperature=0.1
        )
        
        sql_generator = SQLLLMGenerator(config=sql_config, dialect=SQLDialect.POSTGRESQL)
        context = f"{prompt}\n\nRelevant context:\n" + "\n".join(relevant_descriptions)
        sql_query = sql_generator.generate_sql(context)
        
        print(f"  Generated SQL query ({len(sql_query)} characters)")
        
        # Step 4: Write output
        print("Step 4: Writing output...")
        output_dir = Path("./output")
        output_dir.mkdir(exist_ok=True)
        output_file = output_dir / "basic_example.sql"
        
        # Format output with header
        header = f"""-- ===================================================
-- Generated SQL Query - Basic Example
-- ===================================================
-- Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- Original prompt: {prompt}
-- Relevant descriptions: {len(relevant_descriptions)}
-- ===================================================

"""
        
        formatted_sql = header + sql_query
        if not formatted_sql.rstrip().endswith(';'):
            formatted_sql += ';'
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(formatted_sql)
        
        execution_time = time.time() - start_time
        
        # Display results
        print("\n‚úÖ Pipeline completed successfully!")
        print(f"üìÑ SQL written to: {output_file}")
        print(f"‚è±Ô∏è  Execution time: {execution_time:.2f} seconds")
        print(f"üìä Variants generated: {len(variants)}")
        print(f"üéØ Relevant descriptions: {len(relevant_descriptions)}")
        print()
        print("üìã Generated SQL:")
        print("-" * 40)
        print(sql_query)
        print("-" * 40)
        
        return {
            "success": True,
            "sql_query": sql_query,
            "output_file": str(output_file),
            "execution_time": execution_time,
            "variants_count": len(variants),
            "relevant_descriptions": len(relevant_descriptions)
        }
        
    except Exception as e:
        print(f"‚ùå Pipeline failed: {e}")
        return {"success": False, "error": str(e)}


def advanced_example():
    """Advanced usage example with multiple queries and translation."""
    print("\\nüîß Advanced SQL Generation Pipeline Example")
    print("=" * 50)
    
    start_time = time.time()
    
    # Define complex input
    prompt = """
    Create a comprehensive report showing:
    1. Monthly sales trends by product category
    2. Top 10 customers by total purchase value
    3. Products that are running low on inventory
    Include proper joins and aggregate functions
    """
    
    descriptions = [
        "sales table: sale_id, customer_id, product_id, sale_date, quantity, unit_price, total_amount",
        "customers table: customer_id, first_name, last_name, email, registration_date, customer_type",
        "products table: product_id, product_name, category_id, unit_price, stock_quantity, reorder_level",
        "categories table: category_id, category_name, description",
        "inventory table: product_id, current_stock, reserved_stock, last_updated"
    ]
    
    target_dialect = "postgresql"
    
    try:
        # Step 1: Initialize components
        print("Step 1: Initializing components...")
        judge_system = LLMasJudgeSystem()
        
        # Step 2: Generate 5 prompt variants
        print("Step 2: Generating prompt variants...")
        rewrite_result = judge_system.rewrite_text(prompt)
        variants = []
        if rewrite_result and "text1" in rewrite_result:
            variants = [rewrite_result["text1"], rewrite_result["text2"], rewrite_result["text3"]]
        else:
            variants = [prompt]
        
        # Generate additional variants by paraphrasing
        if len(variants) < 5:
            for i in range(5 - len(variants)):
                try:
                    extra_rewrite = judge_system.rewrite_text(variants[0] if variants else prompt)
                    if extra_rewrite and "text1" in extra_rewrite:
                        variants.append(extra_rewrite["text1"])
                except:
                    variants.append(f"Variant {i+1}: {prompt}")
        
        variants = variants[:5]  # Limit to 5
        print(f"  Generated {len(variants)} variants")
        
        # Step 3: Enhanced relevance evaluation
        print("Step 3: Enhanced relevance evaluation...")
        relevant_descriptions = []
        for desc in descriptions:
            relevance_votes = []
            for variant in variants:
                try:
                    is_relevant = judge_system.judge_relevance(variant, desc)
                    relevance_votes.append(is_relevant)
                except:
                    relevance_votes.append(True)  # conservative fallback
            
            # Use 80% confidence threshold
            if sum(relevance_votes) >= len(relevance_votes) * 0.8:
                relevant_descriptions.append(desc)
        
        print(f"  Found {len(relevant_descriptions)} highly relevant descriptions")
        
        # Step 4: Generate multiple SQL queries
        print("Step 4: Generating SQL queries...")
        sql_config = SQLGenerationConfig(
            model_name="microsoft/phi-4-mini-instruct",
            max_new_tokens=512,
            temperature=0.1
        )
        
        sql_generator = SQLLLMGenerator(config=sql_config, dialect=SQLDialect.POSTGRESQL)
        
        # Generate query with full context
        context = f"{prompt}\\n\\nRelevant context:\\n" + "\\n".join(relevant_descriptions)
        primary_query = sql_generator.generate_sql(context)
        
        queries = [primary_query]
        print(f"  Generated primary query ({len(primary_query)} characters)")
        
        # Step 5: Advanced query merging
        print("Step 5: Advanced query merging...")
        merger_system = LLMSQLMergerSystem()
        merge_input = f"Primary query: {primary_query}\\n\\nContext variants: " + "\\n".join(variants[:3])
        merge_result = merger_system.merge_queries(merge_input, detailed=True)
        
        if merge_result.get("success") and merge_result.get("merged_query"):
            merged_query = merge_result["merged_query"]
            merge_strategy = merge_result.get("strategy", "unknown")
            print(f"  Queries merged using {merge_strategy} strategy")
        else:
            merged_query = primary_query
            print("  No merging performed, using primary query")
        
        # Step 6: SQL translation
        print("Step 6: SQL translation to PostgreSQL...")
        translator = SQLTranslator()
        
        from SQLTranlator.sql_translator import SQLDialect as TranslatorDialect
        translation_result = translator.translate(
            sql_query=merged_query,
            target_dialect=TranslatorDialect.POSTGRES,
            source_dialect="generic"
        )
        
        if translation_result.success and translation_result.translated_query:
            final_query = translation_result.translated_query
            print(f"  Successfully translated to PostgreSQL")
        else:
            final_query = merged_query
            print(f"  Translation failed, using original query")
        
        # Step 7: Enhanced output
        print("Step 7: Writing enhanced output...")
        output_dir = Path("./output/advanced")
        output_dir.mkdir(exist_ok=True, parents=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"advanced_example_{timestamp}.sql"
        
        # Create comprehensive header
        header = f"""-- ===================================================
-- Generated SQL Query - Advanced Example
-- ===================================================
-- Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
-- Generated by: NOVASQLAgent Advanced Pipeline
-- Original prompt: {prompt.strip()}
-- Target dialect: {target_dialect}
-- Variants generated: {len(variants)}
-- Relevant descriptions: {len(relevant_descriptions)}/{len(descriptions)}
-- Merge strategy: {merge_strategy if 'merge_strategy' in locals() else 'none'}
-- Translation performed: {'Yes' if 'translation_result' in locals() and translation_result.success else 'No'}
-- ===================================================

"""
        
        formatted_sql = header + final_query
        if not formatted_sql.rstrip().endswith(';'):
            formatted_sql += ';'
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(formatted_sql)
        
        # Write metadata file
        metadata_file = output_dir / f"metadata_{timestamp}.json"
        metadata = {
            "execution_info": {
                "timestamp": datetime.now().isoformat(),
                "execution_time": time.time() - start_time,
                "original_prompt": prompt,
                "target_dialect": target_dialect
            },
            "processing_stats": {
                "variants_generated": len(variants),
                "descriptions_evaluated": len(descriptions),
                "relevant_descriptions": len(relevant_descriptions),
                "queries_generated": len(queries),
                "merge_performed": 'merge_result' in locals() and merge_result.get("success", False),
                "translation_performed": 'translation_result' in locals() and translation_result.success
            },
            "output_files": {
                "sql_file": str(output_file),
                "metadata_file": str(metadata_file)
            }
        }
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        execution_time = time.time() - start_time
        
        # Display detailed results
        print("\\n‚úÖ Advanced pipeline completed successfully!")
        print(f"üìÑ SQL written to: {output_file}")
        print(f"üìÑ Metadata written to: {metadata_file}")
        print(f"‚è±Ô∏è  Total execution time: {execution_time:.2f} seconds")
        print(f"üìä Processing stats:")
        print(f"  - Variants generated: {len(variants)}")
        print(f"  - Relevant descriptions: {len(relevant_descriptions)}/{len(descriptions)}")
        print(f"  - Merge performed: {'Yes' if 'merge_result' in locals() and merge_result.get('success', False) else 'No'}")
        print(f"  - Translation performed: {'Yes' if 'translation_result' in locals() and translation_result.success else 'No'}")
        
        print("\\nüìã Generated SQL (first 10 lines):")
        print("-" * 50)
        sql_lines = final_query.split('\\n')[:10]
        for line in sql_lines:
            print(line)
        if len(final_query.split('\\n')) > 10:
            print("... (more lines)")
        print("-" * 50)
        
        return {
            "success": True,
            "sql_query": final_query,
            "output_file": str(output_file),
            "metadata_file": str(metadata_file),
            "execution_time": execution_time,
            "variants_count": len(variants),
            "relevant_descriptions": len(relevant_descriptions),
            "merge_performed": 'merge_result' in locals() and merge_result.get("success", False),
            "translation_performed": 'translation_result' in locals() and translation_result.success
        }
        
    except Exception as e:
        print(f"‚ùå Advanced pipeline failed: {e}")
        return {"success": False, "error": str(e)}


def configuration_example():
    """Example showing how to work with configuration settings."""
    print("\\n‚öôÔ∏è  Configuration Settings Example")
    print("=" * 50)
    
    # Define configuration for E-commerce Analytics
    config_settings = {
        "pipeline_name": "E-commerce Analytics Pipeline",
        "model": "microsoft/phi-4-mini-instruct",
        "dialect": "bigquery",
        "variants": 4,
        "confidence": 0.75,
        "include_comments": True,
        "max_length": 2500
    }
    
    # Save configuration to file
    config_path = Path("./config/example_config.json")
    config_path.parent.mkdir(exist_ok=True)
    
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(config_settings, f, indent=2, ensure_ascii=False)
    
    print(f"üìù Configuration saved to: {config_path}")
    
    # Load configuration from file  
    with open(config_path, 'r', encoding='utf-8') as f:
        loaded_config = json.load(f)
    
    print(f"üìñ Configuration loaded: {loaded_config['pipeline_name']}")
    print(f"üéØ Target dialect: {loaded_config['dialect']}")
    print(f"üîß Model: {loaded_config['model']}")
    print(f"üìä Variants: {loaded_config['variants']}")
    print(f"üéØ Confidence threshold: {loaded_config['confidence']}")
    
    # Validate configuration
    required_keys = ["pipeline_name", "model", "dialect", "variants", "confidence"]
    issues = []
    for key in required_keys:
        if key not in loaded_config:
            issues.append(f"Missing required key: {key}")
    
    if loaded_config.get("confidence", 0) < 0 or loaded_config.get("confidence", 0) > 1:
        issues.append("Confidence must be between 0 and 1")
        
    if loaded_config.get("variants", 0) < 1 or loaded_config.get("variants", 0) > 10:
        issues.append("Variants must be between 1 and 10")
    
    if issues:
        print("‚ö†Ô∏è  Configuration issues:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("‚úÖ Configuration is valid")
    
    # Demonstrate using configuration with pipeline
    try:
        print("\\nüöÄ Testing configuration with pipeline...")
        
        prompt = "Generate sales report for Q4"
        descriptions = [
            "sales table: id, product_id, customer_id, amount, date",
            "products table: id, name, category, price"
        ]
        
        # Use configuration settings
        judge_system = LLMasJudgeSystem()
        
        # Generate variants using configured count
        rewrite_result = judge_system.rewrite_text(prompt)
        variants = []
        if rewrite_result and "text1" in rewrite_result:
            variants = [rewrite_result["text1"], rewrite_result["text2"], rewrite_result["text3"]]
        
        # Use configured confidence threshold
        relevant_descriptions = []
        for desc in descriptions:
            relevance_votes = []
            for variant in variants[:loaded_config["variants"]]:
                try:
                    is_relevant = judge_system.judge_relevance(variant, desc)
                    relevance_votes.append(is_relevant)
                except:
                    relevance_votes.append(True)
            
            confidence_met = sum(relevance_votes) >= len(relevance_votes) * loaded_config["confidence"]
            if confidence_met:
                relevant_descriptions.append(desc)
        
        print(f"  ‚úÖ Configuration test successful")
        print(f"  üìä Variants processed: {min(len(variants), loaded_config['variants'])}")
        print(f"  üéØ Relevant descriptions: {len(relevant_descriptions)}")
        
    except Exception as e:
        print(f"  ‚ùå Configuration test failed: {e}")
    
    return loaded_config


def error_handling_example():
    """Example showing error handling and recovery."""
    print("\\nüö® Error Handling Example")
    print("=" * 50)
    
    # Test 1: Empty prompt handling
    print("Test 1: Empty prompt handling")
    try:
        judge_system = LLMasJudgeSystem()
        
        # This should handle gracefully 
        empty_prompt = ""
        descriptions = ["some table description"]
        
        # Test with empty prompt
        if not empty_prompt.strip():
            print("‚ùå Empty prompt detected, skipping pipeline execution")
            print("üîß Recovery: Using default prompt")
            empty_prompt = "SELECT * FROM table_name"
        
        rewrite_result = judge_system.rewrite_text(empty_prompt)
        if rewrite_result:
            print("‚úÖ Error handling successful - used recovery prompt")
        else:
            print("‚ö†Ô∏è  Rewriter returned no results")
            
    except Exception as e:
        print(f"üö® Exception in Test 1: {e}")
    
    # Test 2: No descriptions handling
    print("\\nTest 2: No descriptions handling")
    try:
        prompt = "Find all users"
        descriptions = []  # Empty descriptions
        
        judge_system = LLMasJudgeSystem()
        
        if not descriptions:
            print("‚ö†Ô∏è  No descriptions provided")
            print("üîß Recovery: Using default schema assumptions")
            descriptions = ["users table with standard columns: id, name, email"]
        
        # Test relevance with recovered descriptions
        for desc in descriptions:
            try:
                is_relevant = judge_system.judge_relevance(prompt, desc)
                print(f"‚úÖ Relevance check successful: {is_relevant}")
            except Exception as e:
                print(f"‚ùå Relevance check failed: {e}")
                
    except Exception as e:
        print(f"üö® Exception in Test 2: {e}")
    
    # Test 3: SQL Generation with error recovery
    print("\\nTest 3: SQL Generation error recovery")
    try:
        from model.LLMsql import SQLLLMGenerator, SQLGenerationConfig, SQLDialect
        
        # Try with potentially problematic input
        complex_prompt = "Create a very complex query with multiple subqueries and CTEs for data analysis"
        
        sql_config = SQLGenerationConfig(
            model_name="microsoft/phi-4-mini-instruct",
            max_new_tokens=100,  # Intentionally low to test limits
            temperature=0.1
        )
        
        sql_generator = SQLLLMGenerator(config=sql_config, dialect=SQLDialect.POSTGRESQL)
        
        try:
            sql_query = sql_generator.generate_sql(complex_prompt)
            if len(sql_query) > 950:  # Near the limit
                print("‚ö†Ô∏è  Generated query near length limit")
                print("üîß Recovery: Query truncation successful")
            else:
                print("‚úÖ SQL generation within limits")
                
        except Exception as sql_error:
            print(f"‚ùå SQL generation failed: {sql_error}")
            print("üîß Recovery: Using fallback query")
            fallback_query = "SELECT * FROM main_table LIMIT 100;"
            print(f"üìù Fallback query: {fallback_query}")
            
    except Exception as e:
        print(f"üö® Exception in Test 3: {e}")
    
    # Test 4: Translation error handling  
    print("\\nTest 4: Translation error handling")
    try:
        translator = SQLTranslator()
        
        # Test with potentially invalid SQL
        invalid_sql = "INVALID SQL SYNTAX HERE"
        
        from SQLTranlator.sql_translator import SQLDialect as TranslatorDialect
        try:
            result = translator.translate(
                sql_query=invalid_sql,
                target_dialect=TranslatorDialect.POSTGRES,
                source_dialect="generic"
            )
            
            if not result.success:
                print("‚ùå Translation failed as expected with invalid SQL")
                print("üîß Recovery: Using original query")
                print(f"üìù Error: {getattr(result, 'error_message', 'Unknown error')}")
            else:
                print("‚ö†Ô∏è  Translation unexpectedly succeeded")
                
        except Exception as trans_error:
            print(f"üö® Translation exception: {trans_error}")
            print("üîß Recovery: Skipping translation step")
            
    except Exception as e:
        print(f"üö® Exception in Test 4: {e}")
    
    # Test 5: File I/O error handling
    print("\\nTest 5: File I/O error handling")
    try:
        # Test writing to protected directory
        protected_path = Path("/root/protected_file.sql")  # This should fail
        test_content = "SELECT 1;"
        
        try:
            with open(protected_path, 'w') as f:
                f.write(test_content)
            print("‚ö†Ô∏è  Unexpected success writing to protected path")
        except (PermissionError, OSError) as io_error:
            print(f"‚ùå Expected I/O error: {io_error}")
            print("üîß Recovery: Using alternative path")
            
            # Recovery: use current directory
            recovery_path = Path("./recovery_output.sql")
            with open(recovery_path, 'w', encoding='utf-8') as f:
                f.write(test_content)
            print(f"‚úÖ Successfully wrote to recovery path: {recovery_path}")
            
            # Cleanup
            if recovery_path.exists():
                recovery_path.unlink()
                print("üßπ Cleanup completed")
                
    except Exception as e:
        print(f"üö® Exception in Test 5: {e}")
    
    print("\\nüìä Error Handling Summary:")
    print("‚úÖ Empty prompt handling - implemented")
    print("‚úÖ No descriptions recovery - implemented") 
    print("‚úÖ SQL generation limits - handled")
    print("‚úÖ Translation error recovery - implemented")
    print("‚úÖ File I/O error handling - implemented")
    print("\\nüéØ All error scenarios tested successfully!")


def main():
    """Run all examples."""
    print("SQL Generation Pipeline - Usage Examples")
    print("=" * 60)
    
    try:
        # Run examples
        basic_example()
        advanced_example()
        configuration_example()
        error_handling_example()
        
        print("\\nüéâ All examples completed!")
        print("\\nNext steps:")
        print("1. Check the generated SQL files in the ./output directory")
        print("2. Review the configuration file in ./config/example_config.json")
        print("3. Try running the pipeline with your own prompts and descriptions")
        print("4. Use the command-line interface: python main.py --help")
        
    except Exception as e:
        print(f"\\n‚ùå Example execution failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()